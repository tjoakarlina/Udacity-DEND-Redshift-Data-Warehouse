{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abe0ea97",
   "metadata": {},
   "source": [
    "# Create RedShift Cluster using AWS Python SDK\n",
    "\n",
    "This notebook automates the creation of Redshift cluster using AWS Python SDK.\n",
    "It is leveraged from the Udacity Data Engineering Nano Degree sample notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a005e9e1",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "\n",
    "1. You have an AWS Account\n",
    "2. You have setup an IAM User\n",
    "3. You have stored the IAM User access key and secret in the dwh.cfg\n",
    "\n",
    "If you have not done so, please refer to the Readme.MD of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1668c1",
   "metadata": {},
   "source": [
    "## Import required libraries and read the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a089aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE= \"dwh.cfg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e5d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read_file(open(CONFIG_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY                   = config.get('AWS','KEY')\n",
    "SECRET                = config.get('AWS','SECRET')\n",
    "\n",
    "DB_CLUSTER_TYPE       = config.get(\"CLUSTER\",\"DB_CLUSTER_TYPE\")\n",
    "DB_NUM_NODES          = config.get(\"CLUSTER\",\"DB_NUM_NODES\")\n",
    "DB_NODE_TYPE          = config.get(\"CLUSTER\",\"DB_NODE_TYPE\")\n",
    "\n",
    "DB_CLUSTER_IDENTIFIER = config.get(\"CLUSTER\",\"DB_CLUSTER_IDENTIFIER\")\n",
    "DB_NAME               = config.get(\"CLUSTER\",\"DB_NAME\")\n",
    "DB_USER               = config.get(\"CLUSTER\",\"DB_USER\")\n",
    "DB_PASSWORD           = config.get(\"CLUSTER\",\"DB_PASSWORD\")\n",
    "DB_PORT                = config.get(\"CLUSTER\",\"DB_PORT\")\n",
    "\n",
    "DB_IAM_ROLE_NAME      = config.get(\"CLUSTER\", \"DB_IAM_ROLE_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92229687",
   "metadata": {},
   "source": [
    "## Create clients for IAM and Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3498543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client('iam',aws_access_key_id=KEY,\n",
    "                     aws_secret_access_key=SECRET,\n",
    "                     region_name='us-west-2'\n",
    "                  )\n",
    "\n",
    "redshift = boto3.client('redshift',\n",
    "                       region_name=\"us-west-2\",\n",
    "                       aws_access_key_id=KEY,\n",
    "                       aws_secret_access_key=SECRET\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36afbcc2",
   "metadata": {},
   "source": [
    "## Create IAM Role to be able to read S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6677a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#1.1 Create the role, \n",
    "try:\n",
    "    print(\"1.1 Creating a new IAM Role\") \n",
    "    dwhRole = iam.create_role(\n",
    "        Path='/',\n",
    "        RoleName=DB_IAM_ROLE_NAME,\n",
    "        Description = \"Allows Redshift clusters to call AWS services on your behalf.\",\n",
    "        AssumeRolePolicyDocument=json.dumps(\n",
    "            {'Statement': [{'Action': 'sts:AssumeRole',\n",
    "               'Effect': 'Allow',\n",
    "               'Principal': {'Service': 'redshift.amazonaws.com'}}],\n",
    "             'Version': '2012-10-17'})\n",
    "    )    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "print(\"1.2 Attaching Policy\")\n",
    "\n",
    "iam.attach_role_policy(RoleName=DB_IAM_ROLE_NAME,\n",
    "                       PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\"\n",
    "                      )['ResponseMetadata']['HTTPStatusCode']\n",
    "\n",
    "print(\"1.3 Get the IAM role ARN\")\n",
    "roleArn = iam.get_role(RoleName=DB_IAM_ROLE_NAME)['Role']['Arn']\n",
    "\n",
    "print(roleArn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2748706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the roleArn to the config file for the downstream process\n",
    "\n",
    "config.set(\"IAM_ROLE\",\"ARN\", roleArn)\n",
    "\n",
    "with open(CONFIG_FILE, 'w') as configfile:\n",
    "    config.write(configfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6124096",
   "metadata": {},
   "source": [
    "## Create Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = redshift.create_cluster(        \n",
    "        #HW\n",
    "        ClusterType=DB_CLUSTER_TYPE,\n",
    "        NodeType=DB_NODE_TYPE,\n",
    "        NumberOfNodes=int(DB_NUM_NODES),\n",
    "\n",
    "        #Identifiers & Credentials\n",
    "        DBName=DB_NAME,\n",
    "        ClusterIdentifier=DB_CLUSTER_IDENTIFIER,\n",
    "        MasterUsername=DB_USER,\n",
    "        MasterUserPassword=DB_PASSWORD,\n",
    "        \n",
    "        #Roles (for s3 access)\n",
    "        IamRoles=[roleArn]  \n",
    "    )\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc619cc5",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Please wait until the Redshift cluster is ready, before running the next step**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6456c94f",
   "metadata": {},
   "source": [
    "## Describe the Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31254ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettyRedshiftProps(props):\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    keysToShow = [\"ClusterIdentifier\", \"NodeType\", \"ClusterStatus\", \"MasterUsername\", \"DBName\", \"Endpoint\", \"NumberOfNodes\", 'VpcId']\n",
    "    x = [(k, v) for k,v in props.items() if k in keysToShow]\n",
    "    return pd.DataFrame(data=x, columns=[\"Key\", \"Value\"])\n",
    "\n",
    "myClusterProps = redshift.describe_clusters(ClusterIdentifier=DB_CLUSTER_IDENTIFIER)['Clusters'][0]\n",
    "prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb188cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_ENDPOINT = myClusterProps[\"Endpoint\"][\"Address\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b33070",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.set(\"CLUSTER\",\"db_host\", DB_ENDPOINT)\n",
    "\n",
    "with open(CONFIG_FILE, 'w') as configfile:\n",
    "    config.write(configfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b8897d",
   "metadata": {},
   "source": [
    "## Check connection to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce90dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1a8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string=\"postgresql://{}:{}@{}:{}/{}\".format(DB_USER, DB_PASSWORD, DB_ENDPOINT, DB_PORT,DB_NAME)\n",
    "print(conn_string)\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ae9dd",
   "metadata": {},
   "source": [
    "## Clean up resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42897904",
   "metadata": {},
   "source": [
    "### Delete the Redshift Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc60a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift.delete_cluster( ClusterIdentifier=DB_CLUSTER_IDENTIFIER,  SkipFinalClusterSnapshot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4550fa",
   "metadata": {},
   "source": [
    "### Remove the Iam Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7238dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.detach_role_policy(RoleName=DB_IAM_ROLE_NAME, PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess\")\n",
    "iam.delete_role(RoleName=DB_IAM_ROLE_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
